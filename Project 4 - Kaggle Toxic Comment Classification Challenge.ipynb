{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle data source: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\n",
    "\n",
    "We are challenged to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate.\n",
    "\n",
    "Dataset of comments from Wikipedia’s talk page edits.\n",
    "\n",
    "Submissions are now evaluated on the mean column-wise ROC AUC. In other words, the score is the average of the individual AUCs of each predicted column.\n",
    "\n",
    "For each id in the test set, you must predict a probability for each of the six possible types of comment toxicity \n",
    "1. toxic\n",
    "2. severe toxic\n",
    "3. obscene\n",
    "4. threat\n",
    "5. insult\n",
    "6. identity hate)\n",
    "\n",
    "The columns must be in the same order as shown below. The file should contain a header and have the following format:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "\n",
    "1. Preprocess data (use count vectorizer)\n",
    "2. Make your data into 2 columns, X variable: reviews, Y varaible postive/negative\n",
    "3. Train-test split your data\n",
    "4. Train data on linear regression model\n",
    "5. Create 2 spearate document term matrix (words only, bigram)\n",
    "6. Use matplotlib, seaborn to create a confusion matrix to comparese 2 models in terms of F1 score, AUC score\n",
    "7. Use Naive Bayes as well\n",
    "8. Repeat step 1-7 with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations while doing data:\n",
    "1. Data has non-ASCII characters such as Chinese and Japanese characters. Had to remove them\n",
    "2. Creating document term matrix with 159k rows led to Memory Error. not good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re \n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords  # Remove useless words\n",
    "from nltk.chunk import ne_chunk  # Named Entity recognition\n",
    "from nltk.stem.lancaster import LancasterStemmer  # Convert words to base form\n",
    "from nltk.tag import pos_tag  # Helps to recognize whether the word is a noun, adj, etc.\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer, MWETokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# nltk.download()\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 159,571 reviews in the dataset\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.904156\n",
       "1    0.095844\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a bar graph \n",
    "sum_tox = data['toxic'].sum() / 159571 * 100\n",
    "sum_sev = data['severe_toxic'].sum() / 159571 * 100\n",
    "sum_obs = data['obscene'].sum() / 159571 * 100\n",
    "sum_thr = data['threat'].sum() / 159571 * 100\n",
    "sum_ins = data['insult'].sum() / 159571 * 100\n",
    "sum_ide = data['identity_hate'].sum() / 159571 * 100\n",
    "\n",
    "ind = np.arange(6)\n",
    "ax = plt.barh(ind, [sum_tox, sum_sev, sum_obs, sum_thr, sum_ins, sum_ide])\n",
    "\n",
    "plt.xlabel('Percentage (%)')\n",
    "plt.xticks(np.arange(16))\n",
    "plt.title('Percentage of comments that are toxic in various categories')\n",
    "plt.yticks(ind, ('Toxic', 'Severe Toxic', 'Obscene', 'Threat', 'Insult', 'Identity Hate'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = data[('toxic','severe_toxic')].value_counts().plot(kind='barh', figsize=(10,7),\n",
    "#                                         color=\"coral\", fontsize=13);\n",
    "# ax.set_alpha(0.8)\n",
    "# ax.set_title(\"Where were the battles fought?\", fontsize=18)\n",
    "# ax.set_xlabel(\"Number of Battles\", fontsize=18);\n",
    "# ax.set_xticks([0, 5, 10, 15, 20])\n",
    "\n",
    "# # create a list to collect the plt.patches data\n",
    "# totals = []\n",
    "\n",
    "# # find the values and append to list\n",
    "# for i in ax.patches:\n",
    "#     totals.append(i.get_width())\n",
    "\n",
    "# # set individual bar lables using above list\n",
    "# total = sum(totals)\n",
    "\n",
    "# # set individual bar lables using above list\n",
    "# for i in ax.patches:\n",
    "#     # get_width pulls left or right; get_y pushes up or down\n",
    "#     ax.text(i.get_width()+.3, i.get_y()+.38, \\\n",
    "#             str(round((i.get_width()/total)*100, 2))+'%', fontsize=15,\n",
    "# color='dimgrey')\n",
    "\n",
    "# # invert for largest on top \n",
    "# ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      "id               159571 non-null object\n",
      "comment_text     159571 non-null object\n",
      "toxic            159571 non-null int64\n",
      "severe_toxic     159571 non-null int64\n",
      "obscene          159571 non-null int64\n",
      "threat           159571 non-null int64\n",
      "insult           159571 non-null int64\n",
      "identity_hate    159571 non-null int64\n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment_text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment_text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nMore\\nI can\\'t make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It\\'s listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment_text'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there are no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits made under my username hardcore metallica fan were reverted  they weren t vandalisms  just closure on some gas after i voted at new york dolls fac  and please don t remove the template from the talk page since i m retired now        '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text preprocessing steps - remove numbers, capital letters, punctuation, '\\n'\n",
    "import re\n",
    "import string\n",
    "\n",
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "\n",
    "# '[%s]' % re.escape(string.punctuation),' ' - replace punctuation with white space\n",
    "# .lower() - convert all strings to lowercase \n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "# Remove all '\\n' in the string and replace it with a space\n",
    "remove_n = lambda x: re.sub(\"\\n\", \" \", x)\n",
    "\n",
    "# Remove all non-ascii characters \n",
    "remove_non_ascii = lambda x: re.sub(r'[^\\x00-\\x7f]',r' ', x)\n",
    "\n",
    "data['comment_text'] = data['comment_text'].map(alphanumeric).map(punc_lower).map(remove_n).map(remove_non_ascii)\n",
    "\n",
    "data['comment_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d aww  he matches this background colour i m seemingly stuck with  thanks    talk       january       utc '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment_text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey man  i m really not trying to edit war  it s just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page  he seems to care more about the formatting than the actual info '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment_text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  more i can t make any real suggestions on improvement   i wondered if the section statistics should be later on  or a subsection of   types of accidents     i think the references may need tidying so that they are all in the exact same format ie date format etc  i can do that later on  if no one else does first   if you have any preferences for formatting style on references or want to do it yourself please let me know   there appears to be a backlog on articles for review so i guess there may be a delay until a reviewer turns up  it s listed in the relevant form eg wikipedia good article nominations transport   '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment_text'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>d aww  he matches this background colour i m s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man  i m really not trying to edit war  it...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>more i can t make any real suggestions on im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explanation why the edits made under my userna...      0   \n",
       "1  000103f0d9cfb60f  d aww  he matches this background colour i m s...      0   \n",
       "2  000113f07ec002fd  hey man  i m really not trying to edit war  it...      0   \n",
       "3  0001b41b1c6bb37e    more i can t make any real suggestions on im...      0   \n",
       "4  0001d958c54c6e35  you  sir  are my hero  any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An alternative way to process is using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "\n",
    "# for i in data['comment_text']:\n",
    "#     data['new_text'] = TextBlob(i[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's split the data into 6 smaller sections. Each section includes the ID, comment and 1 category for easier analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 159,750 unique observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tox = data.loc[:,['id','comment_text','toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>d aww  he matches this background colour i m s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man  i m really not trying to edit war  it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>more i can t make any real suggestions on im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic\n",
       "0  0000997932d777bf  explanation why the edits made under my userna...      0\n",
       "1  000103f0d9cfb60f  d aww  he matches this background colour i m s...      0\n",
       "2  000113f07ec002fd  hey man  i m really not trying to edit war  it...      0\n",
       "3  0001b41b1c6bb37e    more i can t make any real suggestions on im...      0\n",
       "4  0001d958c54c6e35  you  sir  are my hero  any chance you remember...      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tox.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tox_10k = data.loc[0:10000,['id','comment_text','toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>d aww  he matches this background colour i m s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man  i m really not trying to edit war  it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>more i can t make any real suggestions on im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>congratulations from me as well  use the to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>your vandalism to the matt shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>sorry if the word  nonsense  was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0005300084f90edc</td>\n",
       "      <td>fair use rationale for image wonju jpg  than...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00054a5e18b50dd4</td>\n",
       "      <td>bbq   be a man and lets discuss it maybe over ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>hey    what is it       talk   what is it    a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0006f16e4e9f292e</td>\n",
       "      <td>before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00070ef96486d6f9</td>\n",
       "      <td>oh  and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00078f8ce7eb276d</td>\n",
       "      <td>juelz santanas age  in    juelz santana was...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>bye    don t look  come or think of comming ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000897889268bc93</td>\n",
       "      <td>redirect talk voydan pop georgiev  chernodrinski</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0009801bd85e5806</td>\n",
       "      <td>the mitsurugi point made no sense   why not ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0009eaea3325de8c</td>\n",
       "      <td>don t mean to bother you   i see that you re w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000b08c464718505</td>\n",
       "      <td>regarding your recent edits   once again  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000bfd0867774845</td>\n",
       "      <td>good to know  about me  yeah  i m studying n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000c0dfd995809fa</td>\n",
       "      <td>snowflakes are not always symmetrical    u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000c6a3f0cd3ba8e</td>\n",
       "      <td>the signpost    september      read this s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>000cfee90f50d471</td>\n",
       "      <td>re considering   paragraph edit  i don t un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>000eefc67a2c930f</td>\n",
       "      <td>radial symmetry   several now extinct lineages...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000f35deef84dc4a</td>\n",
       "      <td>there s no need to apologize  a wikipedia arti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000ffab30195c5e1</td>\n",
       "      <td>yes  because the mother of the child in the ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0010307a3a50a353</td>\n",
       "      <td>ok  but it will take a bit of work but i can...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0010833a96e1f886</td>\n",
       "      <td>a barnstar for you        the real life ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>1a67395d931587cd</td>\n",
       "      <td>and i gave you people sources  and that still ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>1a67a4f7d445746c</td>\n",
       "      <td>your accustations towards arcangel  your co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>1a682782dc659340</td>\n",
       "      <td>ko  if you avoid violating the   rule and repe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>1a6930de0c90c08b</td>\n",
       "      <td>treaty of peace with italy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>1a6a64e250b7ae53</td>\n",
       "      <td>edit summary   when editing an article on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>1a6d0771a0b3f861</td>\n",
       "      <td>and his otters    broken clamshells   ott...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>1a6d4a912002da85</td>\n",
       "      <td>the us did not fight at   battle of el alamein</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>1a6d8e02d7fe85a3</td>\n",
       "      <td>chat hi    thanks for adding the two names ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>1a6dd54e3578a98f</td>\n",
       "      <td>dungeon hunter   hey just asking why did you d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>1a6e9383dfe0ba11</td>\n",
       "      <td>sanskrit  suzi    suzika  a  splendid  beautif...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>1a6f5379db374ab5</td>\n",
       "      <td>i was surprised at the speedy launching of t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>1a6ff1035b60dc34</td>\n",
       "      <td>what s going on here    this paragraph in the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>1a700eab31f77b38</td>\n",
       "      <td>so not a rip off   this is  like  the best boo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>1a7078b585a55d89</td>\n",
       "      <td>shakes his head   it s not freaking incorrect...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>1a71635e4e8e91f6</td>\n",
       "      <td>here in my last edits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>1a72e2ac84094285</td>\n",
       "      <td>look i went on the bbc sport website an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>1a733d7c2fcf23dd</td>\n",
       "      <td>february    utc   hey  look  it s that image t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>1a73cbb713474ffc</td>\n",
       "      <td>how terrible that it was there all along  just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>1a73f95fb0374e8c</td>\n",
       "      <td>please note that since i wrote this  i created...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>1a74e6139dcf75c7</td>\n",
       "      <td>i disagree   nobody has yet made a case agains...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>1a759e29797e60c8</td>\n",
       "      <td>good catch    i could  nt see it at first o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>1a75c08b5dfc6f06</td>\n",
       "      <td>no worries here against re adding it i under...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>1a776054de83e16a</td>\n",
       "      <td>see the first bullet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>1a77e058770ad972</td>\n",
       "      <td>as far as i can tell  learned people don t e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1a790ff1007a10e3</td>\n",
       "      <td>numbers may be either listed separately at the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1a7a4868968e2b9e</td>\n",
       "      <td>those two love to disagree  don t they</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1a7c3bec9a71415d</td>\n",
       "      <td>i have changed   lance thomas   to   lance th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1a7c9c14b0cf0fe0</td>\n",
       "      <td>states   courts  i have been putting all artic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1a7d550fec6e9777</td>\n",
       "      <td>will do buddy    but what is this thing about ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1a7d7c88372e5668</td>\n",
       "      <td>hi redrose and apologies for delay  here is a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                       comment_text  \\\n",
       "0      0000997932d777bf  explanation why the edits made under my userna...   \n",
       "1      000103f0d9cfb60f  d aww  he matches this background colour i m s...   \n",
       "2      000113f07ec002fd  hey man  i m really not trying to edit war  it...   \n",
       "3      0001b41b1c6bb37e    more i can t make any real suggestions on im...   \n",
       "4      0001d958c54c6e35  you  sir  are my hero  any chance you remember...   \n",
       "5      00025465d4725e87     congratulations from me as well  use the to...   \n",
       "6      0002bcb3da6cb337       cocksucker before you piss around on my work   \n",
       "7      00031b1e95af7921  your vandalism to the matt shirvington article...   \n",
       "8      00037261f536c51d  sorry if the word  nonsense  was offensive to ...   \n",
       "9      00040093b2687caa  alignment on this subject and which are contra...   \n",
       "10     0005300084f90edc    fair use rationale for image wonju jpg  than...   \n",
       "11     00054a5e18b50dd4  bbq   be a man and lets discuss it maybe over ...   \n",
       "12     0005c987bdfc9d4b  hey    what is it       talk   what is it    a...   \n",
       "13     0006f16e4e9f292e  before you start throwing accusations and warn...   \n",
       "14     00070ef96486d6f9  oh  and the girl above started her arguments w...   \n",
       "15     00078f8ce7eb276d     juelz santanas age  in    juelz santana was...   \n",
       "16     0007e25b2121310b  bye    don t look  come or think of comming ba...   \n",
       "17     000897889268bc93   redirect talk voydan pop georgiev  chernodrinski   \n",
       "18     0009801bd85e5806  the mitsurugi point made no sense   why not ar...   \n",
       "19     0009eaea3325de8c  don t mean to bother you   i see that you re w...   \n",
       "20     000b08c464718505      regarding your recent edits   once again  ...   \n",
       "21     000bfd0867774845    good to know  about me  yeah  i m studying n...   \n",
       "22     000c0dfd995809fa      snowflakes are not always symmetrical    u...   \n",
       "23     000c6a3f0cd3ba8e      the signpost    september      read this s...   \n",
       "24     000cfee90f50d471     re considering   paragraph edit  i don t un...   \n",
       "25     000eefc67a2c930f  radial symmetry   several now extinct lineages...   \n",
       "26     000f35deef84dc4a  there s no need to apologize  a wikipedia arti...   \n",
       "27     000ffab30195c5e1  yes  because the mother of the child in the ca...   \n",
       "28     0010307a3a50a353    ok  but it will take a bit of work but i can...   \n",
       "29     0010833a96e1f886      a barnstar for you        the real life ba...   \n",
       "...                 ...                                                ...   \n",
       "9971   1a67395d931587cd  and i gave you people sources  and that still ...   \n",
       "9972   1a67a4f7d445746c     your accustations towards arcangel  your co...   \n",
       "9973   1a682782dc659340  ko  if you avoid violating the   rule and repe...   \n",
       "9974   1a6930de0c90c08b                      treaty of peace with italy      \n",
       "9975   1a6a64e250b7ae53      edit summary   when editing an article on ...   \n",
       "9976   1a6d0771a0b3f861       and his otters    broken clamshells   ott...   \n",
       "9977   1a6d4a912002da85    the us did not fight at   battle of el alamein    \n",
       "9978   1a6d8e02d7fe85a3     chat hi    thanks for adding the two names ...   \n",
       "9979   1a6dd54e3578a98f  dungeon hunter   hey just asking why did you d...   \n",
       "9980   1a6e9383dfe0ba11  sanskrit  suzi    suzika  a  splendid  beautif...   \n",
       "9981   1a6f5379db374ab5    i was surprised at the speedy launching of t...   \n",
       "9982   1a6ff1035b60dc34  what s going on here    this paragraph in the ...   \n",
       "9983   1a700eab31f77b38  so not a rip off   this is  like  the best boo...   \n",
       "9984   1a7078b585a55d89   shakes his head   it s not freaking incorrect...   \n",
       "9985   1a71635e4e8e91f6                              here in my last edits   \n",
       "9986   1a72e2ac84094285         look i went on the bbc sport website an...   \n",
       "9987   1a733d7c2fcf23dd  february    utc   hey  look  it s that image t...   \n",
       "9988   1a73cbb713474ffc  how terrible that it was there all along  just...   \n",
       "9989   1a73f95fb0374e8c  please note that since i wrote this  i created...   \n",
       "9990   1a74e6139dcf75c7  i disagree   nobody has yet made a case agains...   \n",
       "9991   1a759e29797e60c8     good catch    i could  nt see it at first o...   \n",
       "9992   1a75c08b5dfc6f06    no worries here against re adding it i under...   \n",
       "9993   1a776054de83e16a                              see the first bullet    \n",
       "9994   1a77e058770ad972    as far as i can tell  learned people don t e...   \n",
       "9995   1a790ff1007a10e3  numbers may be either listed separately at the...   \n",
       "9996   1a7a4868968e2b9e    those two love to disagree  don t they            \n",
       "9997   1a7c3bec9a71415d   i have changed   lance thomas   to   lance th...   \n",
       "9998   1a7c9c14b0cf0fe0  states   courts  i have been putting all artic...   \n",
       "9999   1a7d550fec6e9777  will do buddy    but what is this thing about ...   \n",
       "10000  1a7d7c88372e5668  hi redrose and apologies for delay  here is a ...   \n",
       "\n",
       "       toxic  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          1  \n",
       "7          0  \n",
       "8          0  \n",
       "9          0  \n",
       "10         0  \n",
       "11         0  \n",
       "12         1  \n",
       "13         0  \n",
       "14         0  \n",
       "15         0  \n",
       "16         1  \n",
       "17         0  \n",
       "18         0  \n",
       "19         0  \n",
       "20         0  \n",
       "21         0  \n",
       "22         0  \n",
       "23         0  \n",
       "24         0  \n",
       "25         0  \n",
       "26         0  \n",
       "27         0  \n",
       "28         0  \n",
       "29         0  \n",
       "...      ...  \n",
       "9971       0  \n",
       "9972       0  \n",
       "9973       0  \n",
       "9974       0  \n",
       "9975       0  \n",
       "9976       0  \n",
       "9977       0  \n",
       "9978       0  \n",
       "9979       0  \n",
       "9980       0  \n",
       "9981       0  \n",
       "9982       0  \n",
       "9983       0  \n",
       "9984       0  \n",
       "9985       0  \n",
       "9986       0  \n",
       "9987       0  \n",
       "9988       0  \n",
       "9989       0  \n",
       "9990       0  \n",
       "9991       0  \n",
       "9992       0  \n",
       "9993       0  \n",
       "9994       0  \n",
       "9995       0  \n",
       "9996       0  \n",
       "9997       0  \n",
       "9998       0  \n",
       "9999       0  \n",
       "10000      0  \n",
       "\n",
       "[10001 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tox_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sev = data.loc[:,['id','comment_text','severe_toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obs = data.loc[:,['id','comment_text','obscene']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_thr = data.loc[:,['id','comment_text','threat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ins = data.loc[:,['id','comment_text','insult']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ide = data.loc[:,['id','comment_text','identity_hate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Import packages for pre-processing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Import tools to split data and evaluate model performance\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, fbeta_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Import LR, KNN, NB, SVM, DT, RF, XGB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a function that converts the Dataframe into a Count Vectorizer document term matrix.\n",
    "Inputs: Dataframe, label of target variable with '', ngram_range: (1,2)\n",
    "\n",
    "'''\n",
    "\n",
    "def count_vectorizer(df,target):\n",
    "    \n",
    "    # Split the data into X and y data sets\n",
    "    X = df.comment_text\n",
    "    y = df[target]\n",
    "    \n",
    "    # Split our data into training and test data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "    # Create a Count Vectorizer object and remove stopwords from the table\n",
    "    cv1 = CountVectorizer(stop_words='english')\n",
    "    \n",
    "    X_train_cv1 = cv1.fit_transform(X_train)\n",
    "    X_test_cv1  = cv1.transform(X_test)\n",
    "    \n",
    "    # Output a Dataframe of the CountVectorizer with unique words as the labels\n",
    "    test = pd.DataFrame(X_train_cv1.toarray(), columns=cv1.get_feature_names())\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-ab7462a9a273>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcount_vectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_tox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'toxic'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-1cd70fe859d4>\u001b[0m in \u001b[0;36mcount_vectorizer\u001b[1;34m(df, target)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Output a Dataframe of the CountVectorizer with unique words as the labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_cv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    963\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1185\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1187\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count_vectorizer(data_tox, 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tox_10k.shape\n",
    "\n",
    "# Split the data into X and y data sets\n",
    "X = data_tox_10k.comment_text\n",
    "y = data_tox_10k['toxic']\n",
    "    \n",
    "# Split our data into training and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "# Create a Count Vectorizer object and remove stopwords from the table\n",
    "cv1 = CountVectorizer(stop_words='english')\n",
    "    \n",
    "X_train_cv1 = cv1.fit_transform(X_train)\n",
    "X_test_cv1  = cv1.transform(X_test)\n",
    "    \n",
    "# Output a Dataframe of the CountVectorizer with unique words as the labels\n",
    "test = pd.DataFrame(X_train_cv1.toarray(), columns=cv1.get_feature_names())\n",
    "\n",
    "test.shape\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[0:10, 0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[0:1, 30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = test[test.iloc[0:3,:]>= 3 ]     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('genesis')\n",
    "nltk.download('inaugural')\n",
    "nltk.download('nps_chat')\n",
    "nltk.download('webtext')\n",
    "nltk.download('treebank')\n",
    "\n",
    "from nltk.book import *\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "fdist1 = FreqDist(test) \n",
    "\n",
    "fdist1.most_common(20) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1['fuck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a function that converts the Dataframe into a TF-IDF document term matrix \n",
    "'''\n",
    "\n",
    "def tf_idf(df):\n",
    "    \n",
    "    # Split the data into X and y data sets\n",
    "    X = df.comment_text\n",
    "    y = df[target]\n",
    "    \n",
    "    # Split our data into training and test data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Create a Count Vectorizer object and remove stopwords from the table   \n",
    "    tfidf1 = TfidfVectorizer(ngram_range = range, stop_words='english')\n",
    "    X_train_tfidf1 = tfidf1.fit_transform(X_train)\n",
    "    X_test_tfidf1  = tfidf1.transform(X_test)\n",
    "\n",
    "    # Output a Dataframe of the CountVectorizer with unique words as the labels\n",
    "    pd.DataFrame(X_train_tfidf1.toarray(), columns=tfidf1.get_feature_names()).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The second document-term matrix has both unigrams and bigrams, and indicators instead of counts\n",
    "# cv2 = CountVectorizer(ngram_range=(1,2), binary=True, stop_words='english')\n",
    "\n",
    "# X_train_cv2 = cv2.fit_transform(X_train)\n",
    "# X_test_cv2  = cv2.transform(X_test)\n",
    "\n",
    "# pd.DataFrame(X_train_cv2.toarray(), columns=cv2.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try classifying using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression model to use\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the first model\n",
    "lr.fit(X_train_cv1, y_train)\n",
    "y_pred_cv1 = lr.predict(X_test_cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the second model\n",
    "lr.fit(X_train_cv2, y_train)\n",
    "y_pred_cv2 = lr.predict(X_test_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the error metrics, since we'll be doing this several times\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "def conf_matrix(actual, predicted):\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    sns.heatmap(cm, xticklabels=['predicted_negative', 'predicted_positive'], \n",
    "                yticklabels=['actual_negative', 'actual_positive'], annot=True,\n",
    "                fmt='d', annot_kws={'fontsize':20}, cmap=\"YlGnBu\");\n",
    "\n",
    "    true_neg, false_pos = cm[0]\n",
    "    false_neg, true_pos = cm[1]\n",
    "\n",
    "    accuracy = round((true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg),3)\n",
    "    precision = round((true_pos) / (true_pos + false_pos),3)\n",
    "    recall = round((true_pos) / (true_pos + false_neg),3)\n",
    "    f1 = round(2 * (precision * recall) / (precision + recall),3)\n",
    "\n",
    "    cm_results = [accuracy, precision, recall, f1]\n",
    "    return cm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The heat map for the first logistic regression model\n",
    "cm1 = conf_matrix(y_test, y_pred_cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The heat map for the second logistic regression model\n",
    "cm2 = conf_matrix(y_test, y_pred_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all of the error metrics into a dataframe for comparison\n",
    "results = pd.DataFrame(list(zip(cm1, cm2)))\n",
    "results = results.set_index([['Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
    "results.columns = ['LogReg1', 'LogReg2']\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the two models, the first model has better precision, while the second model has better accuracy and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try classifying using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the first Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_cv1, y_train)\n",
    "\n",
    "y_pred_cv1_nb = mnb.predict(X_test_cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the second Naive Bayes model\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_cv2, y_train)\n",
    "\n",
    "y_pred_cv2_nb = bnb.predict(X_test_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the heat map for the first Naive Bayes model\n",
    "cm3 = conf_matrix(y_test, y_pred_cv1_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the heat map for the second Naive Bayes model\n",
    "cm4 = conf_matrix(y_test, y_pred_cv2_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all of the error metrics into a dataframe for comparison\n",
    "results_nb = pd.DataFrame(list(zip(cm3, cm4)))\n",
    "results_nb = results_nb.set_index([['Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
    "results_nb.columns = ['NB1', 'NB2']\n",
    "results_nb\n",
    "\n",
    "results = pd.concat([results, results_nb], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first Naive Bayes model outperforms both Logistic Regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try using TF-IDF instead of Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF versions of the Count Vectorizers created earlier in the exercise\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf1 = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf1 = tfidf1.fit_transform(X_train)\n",
    "X_test_tfidf1  = tfidf1.transform(X_test)\n",
    "\n",
    "tfidf2 = TfidfVectorizer(ngram_range=(1,2), binary=True, stop_words='english')\n",
    "X_train_tfidf2 = tfidf2.fit_transform(X_train)\n",
    "X_test_tfidf2  = tfidf2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the first logistic regression on the TF-IDF data\n",
    "lr.fit(X_train_tfidf1, y_train)\n",
    "y_pred_tfidf1_lr = lr.predict(X_test_tfidf1)\n",
    "cm5 = conf_matrix(y_test, y_pred_tfidf1_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the second logistic regression on the TF-IDF data\n",
    "lr.fit(X_train_tfidf2, y_train)\n",
    "y_pred_tfidf2_lr = lr.predict(X_test_tfidf2)\n",
    "cm6 = conf_matrix(y_test, y_pred_tfidf2_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the first Naive Bayes model on the TF-IDF data\n",
    "mnb.fit(X_train_tfidf1.toarray(), y_train)\n",
    "y_pred_tfidf1_nb = mnb.predict(X_test_tfidf1)\n",
    "cm7 = conf_matrix(y_test, y_pred_tfidf1_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the second Naive Bayes model on the TF-IDF data\n",
    "bnb.fit(X_train_tfidf2.toarray(), y_train)\n",
    "y_pred_tfidf2_nb = bnb.predict(X_test_tfidf2)\n",
    "cm8 = conf_matrix(y_test, y_pred_tfidf2_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all of the error metrics into a dataframe for comparison\n",
    "results_tf = pd.DataFrame(list(zip(cm5, cm6, cm7, cm8)))\n",
    "results_tf = results_tf.set_index([['Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
    "results_tf.columns = ['LR1-TFIDF', 'LR2-TFIDF', 'NB1-TFIDF', 'NB2-TFIDF']\n",
    "results_tf\n",
    "\n",
    "results = pd.concat([results, results_tf], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like using TF-IDF, we were able to improve the recall, but the accuracy and precision of the first Naive Bayes model still outperforms the other models.\n",
    "\n",
    "Overall, the first Naive Bayes model (using unigrams and counts) seems to best classify positive and negative cappuccino cup reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a single subplot\n",
    "f, ax = plt.subplots(1, figsize=(10,5))\n",
    "\n",
    "# Set bar width at 1\n",
    "bar_width = 1\n",
    "\n",
    "# positions of the left bar-boundaries\n",
    "bar_l = [i for i in range(len(data['toxic']))] \n",
    "\n",
    "# positions of the x-axis ticks (center of the bars as bar labels)\n",
    "tick_pos = [i+(bar_width/2) for i in bar_l] \n",
    "\n",
    "# Tabulate the total number of comments which fall into various categories\n",
    "totals = [i+j+k for i,j,k in zip(data['toxic'], data['severe_toxic'], data['obscene'], data['threat'], data['insult'], data['identity_hate'])]\n",
    "\n",
    "# Find the % of comments that are toxic\n",
    "toxic_percent = [i / j * 100 for i,j in zip(data['toxic'], totals)]\n",
    "\n",
    "# Find the % of comments that are severe_toxic\n",
    "severe_percent = [i / j * 100 for  i,j in zip(data['severe_toxic'], totals)]\n",
    "\n",
    "# Find the % of comments that are obscene\n",
    "obscene_percent = [i / j * 100 for  i,j in zip(data['obscene'], totals)]\n",
    "\n",
    "# Find the % of comments that are threat\n",
    "threat_percent = [i / j * 100 for  i,j in zip(data['threat'], totals)]\n",
    "\n",
    "# Find the % of comments that are insult\n",
    "insult_percent = [i / j * 100 for  i,j in zip(data['insult'], totals)]\n",
    "\n",
    "# Find the % of comments that are identity hate\n",
    "obscene = [i / j * 100 for  i,j in zip(data['identity_hate'], totals)]\n",
    "\n",
    "\n",
    "# Create a bar chart in position bar_1\n",
    "ax.bar(bar_l, \n",
    "       # using pre_rel data\n",
    "       toxic_percent, \n",
    "       # labeled \n",
    "       label='Pre Score', \n",
    "       # with alpha\n",
    "       alpha=0.9, \n",
    "       # with color\n",
    "       color='#019600',\n",
    "       # with bar width\n",
    "       width=bar_width,\n",
    "       # with border color\n",
    "       edgecolor='white'\n",
    "       )\n",
    "\n",
    "# Create a bar chart in position bar_1\n",
    "ax.bar(bar_l, \n",
    "       # using mid_rel data\n",
    "       mid_rel, \n",
    "       # with pre_rel\n",
    "       bottom=pre_rel, \n",
    "       # labeled \n",
    "       label='Mid Score', \n",
    "       # with alpha\n",
    "       alpha=0.9, \n",
    "       # with color\n",
    "       color='#3C5F5A', \n",
    "       # with bar width\n",
    "       width=bar_width,\n",
    "       # with border color\n",
    "       edgecolor='white'\n",
    "       )\n",
    "\n",
    "# Create a bar chart in position bar_1\n",
    "ax.bar(bar_l, \n",
    "       # using post_rel data\n",
    "       post_rel, \n",
    "       # with pre_rel and mid_rel on bottom\n",
    "       bottom=[i+j for i,j in zip(pre_rel, mid_rel)], \n",
    "       # labeled \n",
    "       label='Post Score',\n",
    "       # with alpha\n",
    "       alpha=0.9, \n",
    "       # with color\n",
    "       color='#219AD8', \n",
    "       # with bar width\n",
    "       width=bar_width,\n",
    "       # with border color\n",
    "       edgecolor='white'\n",
    "       )\n",
    "\n",
    "# Set the ticks to be first names\n",
    "plt.xticks(tick_pos, df['first_name'])\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.set_xlabel(\"\")\n",
    "\n",
    "# Let the borders of the graphic\n",
    "plt.xlim([min(tick_pos)-bar_width, max(tick_pos)+bar_width])\n",
    "plt.ylim(-10, 110)\n",
    "\n",
    "# rotate axis labels\n",
    "plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "# shot plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
